---
title:  "[Section2] 선형/로지스틱 회귀"
excerpt: "AIB 컨텐츠 복습 챌린지"

categories:
- AIB2 Study

toc: True
toc_sticky: True

date: 2021-10-24
last_modified_at: 2021-10-24
---
# [Section2] 선형/로지스틱 회귀

<br>

## 선형/ 로지스틱 회귀

```
3. 과적합/과소적합이 무엇인지 이해하기
    과적합, 과소적합에서 경사하강법은 어떤 관련이 있을까?
4. 범주형(Cagegorical) 자료를 다루기 위한 원핫인코딩(One-hot encoding) 무엇인지와 왜 사용하는지 알아보기
5. 훈련/검증/테스트(train/validate/test) 데이터를 분리하는 이유는 뭘까?
6. 선형회귀의 기본적인 개념은 무엇이 있는지 알아보자
```

### 회귀 vs 분류

![image](https://user-images.githubusercontent.com/76996686/138236555-42f79457-8466-4445-bc61-79d27652378f.png)

<br>

### Dataset 분리

- Overfitting 방지를 위해 Dataset을 train/test로 분리
- 모델링의 목표는 Test 데이터를 잘 맞추는 것

1. Dataset -> Train/Test
2. Train -> Train/Validation
3. Train 데이터로 모델 학습 후, Validation으로 검증
4. 검증 후 Train과 Validation을 합쳐서 학습 후 Test 데이터 확인
   - 기존 training set만을 사용하였던 모델의 파라미터와 구조는 그대로 사용하지만, 전체 데이터를 사용하여 다시 학습시킴으로써 모델이 조금 더 튜닝되도록 함

<br>

> Validation 나누는 이유

- Validation set(검정 데이터)은 training set으로 만들어진 모델의 성능을 측정하기 위해 사용
-  일반적으로 어떤 모델이 가장 데이터에 적합한지 찾아내기 위해서 다양한 파라미터와 모델을 사용해보게 되며, 그 중 validation set으로 가장 성능이 좋았던 모델을 선택
-  이후 Test set으로 마지막 확인 필요

<br>

> Validation set vs Test set

- Validation set -> 여러 모델들 각각에 적용되어 성능 측정하여 최종 모델 선정
- Test set -> validation을 통해 선정된 최종 모델에 대해, 앞으로 기대되는 성능 예측위해 사용

<br>

- `train_test_split`

```python
from sklearn.model_selection import train_test_split

# train-test분리
X_train, X_test, y_train, y_test = train_test_split(df['feature'],df['target'])

# train-validation분리
X2_train, X2_val, y2_train, y_val = train_test_split(X_train, y_train)
```

- `test_size` : 테스트 셋 구성의 비율(default값은 0.25)
- `shuffle` : split을 해주기 이전에 섞을것인가 의 여부(default = True)
- `stratify` : classification을 다룰때에는 매우 중요한 옵션값. stratify 값을 target으로 지정해주면 각각의 class비율(ratio)을 train/validation에 유지해 줌 (한쪽에 쏠려 분배되는것을 방지)
- `random_state`: 세트를 섞을때 해당 int값을 보고 섞으며, 하이퍼 파라미터를 튜닝시 이 값을 고정해두고 튜닝해야 매번 데이터셋이 변경되는 것을 방지

<br>

### 과적합/과소적합

#### Overfitting

- 너무 복잡한 모델을 생성하는 바람에 학습 데이터에는 굉장히 잘 맞지만 새로운 데이터에는 잘 맞지 않는 현상

#### Underfitting

- 너무 단순한 모델을 생성하여 학습 데이터와 잘 맞지 않는 현상