---
title:  "[Section2] 머신러닝 개요 및 프로세스 / SVM"
excerpt: "AIB 컨텐츠 복습 챌린지"

categories:
- AIB2 Study

toc: True
toc_sticky: True

date: 2021-10-24
last_modified_at: 2021-10-24
---
# [Section1] 머신러닝 개요 및 프로세스 / SVM

<br>

## 머신러닝


### 머신러닝이란

- 다양한 알고리즘 및 규칙을 데이터를 기반으로 하여 스스로 학습하여 성능을 항샹 시키는 기법

<br>

### vs 딥러닝

- 머신러닝의 한 방법
- 데이터 양이 많을 수록 성능 증가
- 그래서 딥러닝을 위한 고사양의 CPU, GPU 등의 하드웨어 필요

<br>

### 머신러닝 프로세스

1. 문제 정의
   - 현재 상황 파악
   - 프로젝트 목적 정의
   - 성능 평가 지표 선택
2. 데이터 수집
   - 데이터 수집
   - 데이터셋 살펴보기
3. EDA
  - 데이터 분포 조사
  - 상관 관계 조사
  - 시각화
4. Preprocessing
   - 결측치, 이상치 처리 (`SimpleImputer`)
   - Encoding
   - Scaling
     - Mix-Max Scaling : 0~1 범위로 값 조정(`MinMaxScaler()`)
     - Standardization : 평균을 빼고 표준편차로 나누어 결과 분포의 분산이 1이 되도록 함 (`StandarScaler()`)
     - train set에 `fit()` 적용 후, train set/test set에 `transform()`
   - Train/Validation/Test 분리
     - `train_test_split `
     - 사이킷런의 `k-겹 교차 검증(k-fold cross-validation)` 기능 사용
5. Modeling
   - Model 선택
   - 파라미터 튜닝
   - 훈련 및 val 평가

<br>

## SVM(Support Vector Machine)

- `결정 경계(Decision Boundary)`, 즉 분류를 위한 기준 선을 정의하는 모델, 그래서 분류되지 않은 새로운 점이 나타나면 경계의 어느 쪽에 속하는지 확인해서 분류 과제를 수행

<br>

![image](https://user-images.githubusercontent.com/76996686/138594011-d7853cbb-555b-4cba-a6a9-47060f18d3e1.png)

<br>

- Support Vectors : Decision Boundary와 가까이 있는 데이터 포인트, n개의 속성을 가진 데이터에는 최소 n+1개의 SV가 존재
- Margin : Decision Boundary와 Support Vector 사이의 거리
  - Hard Margin : 이상치를 허용하지 않게 까다롭게 기준을 세움, 서포트 벡터와 결정 경계 사이의 거리가 매우 좁다.(=Margin이 작음) -> Overfitting 문제 발생 가능
  - Soft Margin : 이상치 허용할 수 있도록 너그럽게 기분 세움, 서포트 벡터와 결정 경계 사이가 매우 멀어짐(=Margin이 큼) -> Underfitting 문제 발생 가능
  - ![image](https://user-images.githubusercontent.com/76996686/138594257-11134b31-896a-44b8-883a-44425422d0dc.png)


> 최적의 Decision Boundary는 Migin을 최대화 한다.

<br>

### SVM in scikit-learn

- Scikit-learn에서 SVM모델이 오류를 얼마나 허용할지 파라미터 `C` 제공
```python
from sklearn.svm import SVC
classifier = SVC(kernel = 'linear') # 'linear'/ 'ploy' / 'rbf'(default)

classifier = SVC(C = 0.01) # C 값이 클수록 Hard Margin, 작을수록 Soft Margin
```

- 파라미터 `gamma` : 결정 경계를 얼마나 유연하게 그릴 것인지 결정
```python
# gamma 클수록 구불구불(overfitting)/ 작을수록 직선(underfitting)
classifier = SVC(kernel = "rbf", C = 2, gamma = 0.5) 
```