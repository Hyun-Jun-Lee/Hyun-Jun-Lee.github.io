---
title:  "[Section4] CNN"
excerpt: "AIB 컨텐츠 복습 챌린지"

categories:
- AIB2 Study

toc: True
toc_sticky: True

date: 2021-11-10
last_modified_at: 2021-11-10
---
# [Section4] CNN

<br>

## Convolutional Neural Network

### CNN의 유용성

- CNN이 나오기 이전, 이미지 인식은 2차원으로 된 이미지(채널까지 포함해서 3차원)를 1차원배열로 바꾼 뒤 FC(Fully Connected)신경망으로 학습시키는 방법

![image](https://user-images.githubusercontent.com/76996686/140971582-a9fd2861-59b6-40b5-8706-f02599c6066f.png)

- 위와 같은 방법은 이미지를 평면화 시키는 과정에서 정보가 손실되어 정확도를 높이는데 한계가 있었고, 이런 단점을 보완하여 이미지의 공간정보를 유지한채 학습을 하게하는 모델이 CNN

<br>

### Convolutional?

![image](https://user-images.githubusercontent.com/15958325/58780750-defb7480-8614-11e9-943c-4d44a9d1efc4.gif)

<br>

- 노란색의 Convolution filter(or Kernel)이 사용자가 설정한 `stride`에 칸을 이동
- 각 위치의 곱셈 후 합한 결과를 Convolved Feature에 출력하고 이것을 `feature map` 이라고 함.

<br>

### Padding

- Convolution 레이어에서는 Filter와 Stride의 작용으로 Feature map의 크기는 입력데이터보다 작아진다(이미지 안쪽과 달리 테두리는 적은 횟수만 filter됨)
- 이것을 방지하기 위한 방법이 `Padding`

![image](https://user-images.githubusercontent.com/76996686/140973615-04c10cb5-d58a-43de-b7d9-68bb7f2f7a9d.png)

<br>

```python
# same = padding이 존재하여 입력과 출력의 크기는 같음 / valid = padding 0을 뜻함,즉 입력보다 출력의 크기가 작아짐
model.add(Conv2D(64, (2, 2), activation='relu', padding='same'))
```

<br>

### Pooling

- 이미지의 크기를 계속 유지한 채 FC(Fully Connected)레이어로 가게 된다면 연산량이 기하급수적으로 늘어나게 됨
- Pooling layer는 특성을 유지한채로 차원을 줄여 연산을 효율적으로 하게해주는 역활

![image](https://user-images.githubusercontent.com/76996686/140976551-9d0924ef-892f-464c-bd58-a0cbaf9630d5.png)


 > CNN에서는 뉴런이 가장 큰 신호에 반응하는 것과 유사한 Max Pooling 기법 주로 사용

 - 일반적으로 pooling의 크기와 stride의 크기를 같게 설정하여 모든 원소가 한번씩은 처리가 되도록 설정

<br>

## CNN 전체 구조

![image](https://user-images.githubusercontent.com/76996686/140976933-70734a7c-a77f-4907-b92b-9d1e705251fc.png)

- 특징 추출 단계(Feature Extraction)
  - Convolution Layer : Filter 통해 이미지의 특징을 추출
  - Pooling Layer : 특징을 강화시키고 이미지 크기 조절
  - Convolution과 Pooling을 반복하면서 이미지의 feature를 추출

- 이미지 분류 단계(Classification)
  - Flatten Layer : 데이터 타입을 FC네트워크 형태로 변경. 입력데이터의 shape 변경만 수행
  - Softmax Layer : Classification수행

## mnist CNN Python Code

```python
import tensorflow as tf
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers.convolutional import Conv2D, MaxPooling2D
import numpy as np

img_rows = 28
img_cols = 28

(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

input_shape = (img_rows, img_cols, 1)
x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)
x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)

x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.

print('x_train shape:', x_train.shape)
print(x_train.shape[0], 'train samples')
print(x_test.shape[0], 'test samples')

batch_size = 128
num_classes = 10
epochs = 12  

y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

model = Sequential()
model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1), padding='same', activation='relu', input_shape=input_shape))
model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
model.add(Conv2D(64, (2, 2), activation='relu', padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(1000, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(num_classes, activation='softmax'))
model.summary()

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
hist = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))

score = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

# 결과 그림으로 확인
import random
import matplotlib.pyplot as plt

predicted_result = model.predict(x_test)
predicted_labels = np.argmax(predicted_result, axis=1)

test_labels = np.argmax(y_test, axis=1)

count = 0

plt.figure(figsize=(12,8))
for n in range(16):
    count += 1
    plt.subplot(4, 4, count)
    plt.imshow(x_test[n].reshape(28, 28), cmap='Greys', interpolation='nearest')
    tmp = "Label:" + str(test_labels[n]) + ", Prediction:" + str(predicted_labels[n])
    plt.title(tmp)

plt.tight_layout()
plt.show()
```

<br>

## ResNet

- 마이크로소프트에서 개발한 알고리즘
- 모델의 Layer가 깊어질수록 Gradient vanishing 문제 때문에 오히려 성능이 떨어짐
    - Gradient vanishing : layer가 깊어질수록 미분을 점점 많이 하기 때문에 backpropagation을 해도 앞의 layer일수록 미분값이 작아져 그만큼 output에 영향을 끼치는 weight 정도가 작아지는 것
- ResNet은 Skip connection을 이용한 residual learning을 통해 layer가 깊어짐에 따른 gradient vanishing 문제를 해결

<br>

### Residual learning

- 기존 netural net의 학습 목적은 input(x)을 타겟값(y)으로 mapping하는 함수 H(x)를 찾는 것, 따라서 H(x)-y를 최소화하는 방향으로 학습을 진행
- 이미지 classification의 경우 x에 대한 타겟값 y는 사실 x를 대변하는 것으로, y와 x의 의미가 같게 mapping해야함
  - ex) 강아지 사진의 pixel값이 input(x)로 주어질때 이를 2개의 label중 강아지가 1에 해당한다면, 타겟값(y)를 1로 정해서 학습하는 것이 아닌 강아지 사진의 pixel값 (x)로 y를 mapping해야한다.
- 따라서 네트워크의 출력값이 x가 되도록 `H(x)-x`를 최소화하는 방향으로 학습, `F(x) = H(x) - x`를 잔차라고 하며 이 잔차를 학습하는 것을 `Residual learning` 이라고 함

<br>

### Skip connection

![image](https://user-images.githubusercontent.com/76996686/141023514-a8fc66f8-188a-46dc-b731-f1abfd8592e1.png)

- 기존 CNN은 feature(x)가 입력되면 여러 layer를 거쳐 H(x)가 출력

<br>

![image](https://user-images.githubusercontent.com/76996686/141023577-e608640a-2c39-4b24-808b-7a4a83385307.png)

- 이전 layer에서 사용되었던 feature(x= 2 layer 이전 feature, F(x)= 바로 직전 feature)를  connection하여 H(x)를 출력
- H(x) = F(x) + x

<br>

### ResNet prac

https://brillante-scene.tistory.com/94

