---
title:  "[Section2] 데이터불균형 문제와 XAI"
excerpt: "AIB 컨텐츠 복습 챌린지"

categories:
- AIB2 Study

toc: True
toc_sticky: True

date: 2021-11-02
last_modified_at: 2021-11-02
---
# [Section2] 데이터불균형 문제와 XAI

<br>

## XAI(eXplainable AI, 설명가능 인공지능)

- AI의 Black Box 구조 탓에 상용화가 쉽지 않기에, AI를 통한 결과를 올바르게 해석하고 과정을 설명가능 하도록 해주는 기술

<br>

### XAI 종류

<br>

<br>

##### Instrinsic

- 모델을 쉽게 해석할 수 있는 가장 빠른 방법은 애초에 모델을 해석 가능한 구조로 고안하는 것으로 구조가 단순한 모델은 구조만 보더라도 해석력을 가지고 있다고 해서 Intrinsic(본래 갖추어진) 이라는 이름이 붙음.


- Decision Tree
  - 예측 결과를 도출해내는 과정과 해석이 직관적
  - 예측 결과에 해당하는 마디를 따라 올라가면서 의사결정의 근거 쉽게 확인 가능

- Linear Model
  - 독립 변수의 계수가 곧 독립 변수의 중요도를 의미
  - 또는 L1 regularization을 적용하면 일부 독립변수의 계수가 0인 Sparse Linear Model(희소 선형 모델)이 되는데, 이 경우 예측 결과에 영향을 미치는 독립 변수만 추릴 수 있으므로 설명력을 갖게 됨.

<br>

##### Post-Hoc

- 모델 자체가 설명력이 부족할 경우, 에측결과를 사후 해석(ML/DL 분야 해석 기법이 대부분 post-hoc)

<br>

#### Scope

- 설명하는 범위에 따라 해석 기법 분류
- 모든 예측 결과에 대해서 항상 설명력을 갖는 전역적인(Global) 기법과 하나 또는 일부 예측 결과만 설명 가능한 국소적인(Local) 기법

<br>

##### Global

- 모델의 로직과 관련된 이해를 바탕으로, 모델이 예측하는 모든 결과를 설명 or 모듈 레벨에서 모델의 한 모듈이 예측 결과에 어떻게 영향을 미치는지 설명하는 범위도 포함
- Global은 이상적인 설명 기법이지만 Post-hoc을 Global로 구현하기는 현실적으로 까다롭다. 설명 측면에서, 모든 예측에 대해서는 일정한 설명력을 갖출 수 있더라도, 개별 예측 결과의 특징을 설명하는 능력은 다소 떨어질 수 있다.

<br>

##### Local

- 특정한 의사 결정 또는 하나의 예측 결과만 설명
- 설명할 범위가 적어서 비교적 실현성 있고 비용이 적게 듬

<br>

- LIME(Local Interpretable Model-agnostic Explanation)
  - 입력값을 교란(perturb)해 예측이 어떻게 바뀌는지를 확인함으로써 중요한 입력 변수를 찾는 방법
  - Model에 대해 영향을 받지 않기 때문에 어떤 알고리즘에도 사용할 수 있음

<br>

#### Dependency

- 특정 종류의 모델에만 적용할 수 있도록 특화되었는지, 혹은 모델에 관계 없이 범용적으로 적용할 수 있는지에 따라 분류

<br>

##### model-specific

- 특정 종류의 모델만 적용할 수 있는 설명 기법

<br>

- Activation
  - CNN 계열의 모델에서 활성 함수를 거쳐 활성화(Activation)된 feature map 또는 weight 자체를 시각화함으로써 모델을 설명하려는 시도
  - 특정 예측 결과를 설명하는 것이 아니라 Convolution Layer의 weight를 통해서 전역적인 예측 결과를 설명

- Maximization Optimization
  - 활성 함수를 최대한으로 활성화하는 최적의 이미지를 생성함으로써 feature map이 갖는 의미를 파악하는 방법
    1. 랜덤 노이즈 이미지를 입력값, 특정 feature map을 타겟 출력값으로 설정
    2. 타겟 출력값을 입력값으로 미분하여 feature map을 활성화 시키는 값을 구함
    3. 그 값을 입력값에 더해주면 입력값 보다 feature map을 더 많이 활성화하는 이미지 찾을수 있음
    4. 위 과정을 반복해 활성홤수를 최대 활성화 시키는 이미지를 얻을 수 있음

- CAM(Class Activation Map)
  - 이미지 분류 모델에서 이미지의 어느 부분을 보고 class를 예측했는지를 시각화
  - 마지막 feature map을 꺼내와서 채널별로 대응하는 weight를 곱한 후 모두 더해주면 모델이 어느 부분을 보고 class를 분류 했는지 알 수 있음

<br>

#### Model-agnostic

- 모델의 내부는 사람이 알 수 없으므로, 모델을 설명하기 위해서는 모델 밖에서 근거를 찾아야 한다는 방법으로 모델의 특성을 사용하지 않음


<br>

- Surrogate
  - 설명 불가능한 모델 대신에 설명 가능한 대리(Surrogate) 모델을 따로 만들어서 설명하는 방법이다. 보통 Surrogate 모델로는 설명이 가능한 Intrinsic 모델을 사용
  - 대리모델은 Original(원본) 모델의 예측을 정답으로 삼아 지도 학습(Supervised Learing)

- Sensitivity Analysis
  - 입력 변수를 의도적으로 교란하거나 데이터를 변형 시뮬레이션했을 때 모델의 예측이 안정적으로 유지되는지를 확인하는 기법
  - 입력 변수의 변화에 따른 예측의 변화를 측정하여 변수의 중요도를 해석

- PDP(Partial Dependence Plot)
  - PDP는 모델의 예측이 단일 입력에 어떻게 의존하는지를 보여주는 1-way 그래프
  - 예측이 관심 입력 변수의 값에 부분적으로 영향을 받는 것인지 나타냄
  - 관심있는 특정 입력변수를 제외한 다른 입력변수들의 값은 고정시킨 상태(상수 취급)에서 관심있는 입력변수의 값을 변화시키며(변수 취급) 예측값을 계산한 후, 그 값들의 평균을 낸 것

<br>

## 데이터 불균형 문제

### 데이터 불균형의 문제점

- 데이터가 불균형하다면 분포도가 높은 클래스에 모델이 가중치를 많이 두려고 함
- 불균형 문제를 해결하지 않으면 모델은 가중치가 높은 클래스를 더 예측하려고 하기 때문에 Accuracy는 높아질 수 있지만 분포가 작은 값에 대한 Precision은 낮을 수 있고, 분포가 작은 클래스의 재현율이 낮아지는 문제가 발생
- ex) 분포가 100개의 데이터에서 1과 0값이 각각 97 : 3 비율을 가지고 있을 때 모든 값을 1로 예측한다 하더라도 정확도가 97% 나오게 e됨

<br>

### Under Sampling

- 데이터의 분포가 높은 값을 낮은 값으로 맞춰주는 작업
- 유의미한 데이터만 남길 수 있지만, 정보가 유실 됨
  - Random Under Sampling : 무작위 샘플링
  - Tomek link : 서로 다른 클래스가 있을 때 서로 다른 클래스끼리 가장 가까운 데이터들이 토멕링크로 묶여서 토멕링크 중 분포가 높은 데이터를 제거하는 방법<br>
  ![image](https://user-images.githubusercontent.com/76996686/139864186-87b1846c-b267-4939-b63f-9bb1f18e8e28.png)

<br>

### Over Sampling

- 분포가 작은 클래스의 값을 분포가 큰 클래스로 맞춰주는 샘플링 방법
- 정보의 손실을 막을 수 있지만, 여러 유형의 관측치를 다수 추가하기 때문에 Overfitting 위험
  - ADASYN
    - 소수 클래스 데이터와 그 데이터에서 가장 가까운 k개의 소수 클래스 데이터 중 무작위로 선택된 데이터 사이의 직선상에 가상의 소수 클래스 데이터를 만드는 방법<br>
    ![image](https://user-images.githubusercontent.com/76996686/139867642-ab433894-57c6-4060-9b3e-613631d46bd2.png)

  - SMOTE
    - 임의의 소수 클래스 데이터로부터 인근 소수 클래스 사이에 새로운 데이터를 생성하는 방법
    - 임의의 소수 클래스인 관측치 X 설정, X와 가까운 K개의 이웃을 찾고 K개의 이웃과 X사이에 임의의 데이터를 생성하는 것